{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Build and Train a Model\n",
    "In this notebook we preprocess the data to get it ready for a model, extend a pre-trained model from Keras, train the model on\n",
    "the x-ray images in our dataset, and evaluate that models performance.\n",
    "\n",
    "The goal is to be able to accurately classify pneumonia from only looking at the x_ray image with a reasonable level of accuracy.\n",
    "Finding a baseline accuracy for this task is more complicated than just considering how often the model correctly classifies\n",
    "pneumonia vs not pneumonia. Pneumonia is rare in our dataset (1.276%) so a naive model could just classify every image as not pneumonia\n",
    "do very well (98.724% Accurate). Therefore we will use other metrics like Recall, Precision, and F1 Score to evaluate our model.\n",
    "This [paper](https://arxiv.org/pdf/1711.05225.pdf) goes into detail on finding a good baseline accuracy. According to this paper\n",
    "the average radiologist F1 score for detecting pneumonia from x_ray images with no other information about the patients\n",
    "is 0.387 (based on the radiologist they used for this study). I hope to build a model that can come close to this baseline or\n",
    "even outperform it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Necessary Packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from random import sample\n",
    "from sklearn import model_selection, metrics\n",
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Data\n",
    "In this section we setup the data to get it ready for our model. I parse the `Finding Label` to make create binary\n",
    "classification labels for each type of disease for every observation. I also create a `path` column for each `Image Index`\n",
    "so I can get to the location of the actual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the Data\n",
    "all_xray_df = pd.read_csv('/data/Data_Entry_2017.csv')\n",
    "\n",
    "# Convert `Finding Labels` to binary labels for each disease\n",
    "all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "for label in all_labels:\n",
    "    if len(label)>1:\n",
    "        all_xray_df[label] = all_xray_df['Finding Labels'].map(lambda diseases: 1.0 if label in diseases else 0)\n",
    "\n",
    "# Create 'path' column for each 'Image Index'\n",
    "all_image_paths = {os.path.basename(x): x for x in\n",
    "                   glob(os.path.join('/data','images*', '*', '*.png'))}\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
    "\n",
    "# Check the results\n",
    "print(f'Images Found: {len(all_image_paths)}, Total Observations: {all_xray_df.shape[0]}')\n",
    "all_xray_df.sample(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Validation Sets\n",
    "In this section I create the training and validation sets for the model. I am using an 90/10 split of the data with\n",
    "90% of the positive pneumonia cases in the training set and 10% of the positive pneumonia cases in the validation set.\n",
    "Also for the training set the proportion of positive to negative pneumonia cases will be 50/50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_xray_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-321c498bf99f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     29\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m \u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_splits\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_xray_df\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'all_xray_df' is not defined"
     ]
    }
   ],
   "source": [
    "def create_splits(df, validation_percent):\n",
    "    # create original train / validation split\n",
    "    train_data, val_data = model_selection.train_test_split(df, test_size=validation_percent, stratify=df['Pneumonia'])\n",
    "\n",
    "    # Update training set to be 50/50 split\n",
    "    pos_indexes = train_data[train_data.Pneumonia == 1].index.tolist()\n",
    "    neg_indexes = train_data[train_data.Pneumonia == 0].index.tolist()\n",
    "    neg_sample = sample(neg_indexes, len(pos_indexes))\n",
    "    train_data = train_data.loc[pos_indexes+neg_sample]\n",
    "\n",
    "    # Check splits\n",
    "    print(f'Total Pneumonia Cases: {df[df.Pneumonia==1].shape[0]} \\\n",
    "    {(1-validation_percent)*100}% Pneumonia Cases: {int(df[df.Pneumonia==1].shape[0]*(1-validation_percent))} \\\n",
    "    {validation_percent*100}% Pneumonia Cases: {int(df[df.Pneumonia==1].shape[0]*validation_percent)}')\n",
    "    print(f'Pneumonia Cases in Training set: {train_data[train_data.Pneumonia==1].shape[0]} \\\n",
    "    Pneumonia Cases in Validation set: {val_data[val_data.Pneumonia==1].shape[0]}')\n",
    "\n",
    "    print(f'Train Set Size: {train_data.shape[0]}, \\\n",
    "    Pos %: {train_data[train_data.Pneumonia==1].shape[0] / train_data.shape[0] *100}, \\\n",
    "    Neg %: {train_data[train_data.Pneumonia==0].shape[0] / train_data.shape[0] *100}')\n",
    "\n",
    "    print(f'Original Set Size: {df.shape[0]} \\\n",
    "    Pos %: {df[df.Pneumonia==1].shape[0] / df.shape[0] *100} \\\n",
    "    Neg %: {df[df.Pneumonia==0].shape[0] / df.shape[0] *100}')\n",
    "\n",
    "    print(f'Validation Set Size: {val_data.shape[0]}, \\\n",
    "    Pos %: {val_data[val_data.Pneumonia == 1].shape[0] / val_data.shape[0] *100}, \\\n",
    "    Neg % {val_data[val_data.Pneumonia == 0].shape[0] / val_data.shape[0] *100}')\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "train_df, val_df = create_splits(all_xray_df, 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Image Augmentation and Setup Data Generators\n",
    "In this section I set up image augmentation to generate a more diverse training set, and create training and validation\n",
    "set generators to use for model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Create Image Data Generator for training set\n",
    "train_idg = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                         horizontal_flip = True,\n",
    "                         vertical_flip = False,\n",
    "                         rotation_range = 0.5,\n",
    "                         shear_range = 0.1,\n",
    "                         zoom_range = 0.15)\n",
    "\n",
    "train_generator = train_idg.flow_from_dataframe(dataframe=train_df, directory=None,\n",
    "                                          x_col='path', y_col='Pneumonia',\n",
    "                                          class_mode = 'raw', target_size=IMG_SIZE, batch_size=64)\n",
    "\n",
    "# Create a generator for the test set\n",
    "validation_idg = ImageDataGenerator(rescale=1.0/255.0)\n",
    "validation_generator = validation_idg.flow_from_dataframe(dataframe=val_df, directory=None,\n",
    "                                                      x_col='path', y_col='Pneumonia',\n",
    "                                                      class_mode='raw', target_size=IMG_SIZE, batch_size=1024,\n",
    "                                                      shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a random batch of training data to make sure everything looks okay\n",
    "# Training Examples\n",
    "t_x, t_y = next(train_generator)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    if c_y == 1: \n",
    "        c_ax.set_title('Pneumonia')\n",
    "    else:\n",
    "        c_ax.set_title('No Pneumonia')\n",
    "    c_ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending a Pre-trained Model\n",
    "In this section I use pre-trained models from Keras to attempt to solve this classification problem. I used the\n",
    "VGG19 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to setup our own model that is an extension of already pre trained model\n",
    "def setup_model(model, input_shape, output_size: int, dropout: bool, num_active_layers: int, lr):\n",
    "    # Creat new network based on parameters\n",
    "    new_model = tf.keras.Sequential()\n",
    "    new_model.add(tf.keras.layers.Input(shape=input_shape, dtype='float32'))\n",
    "\n",
    "    # Setup Fully Connected Layers (CURRENTLY HARDCODED FOR VGG19)\n",
    "    if dropout:\n",
    "        for layer in model.layers[:-3]:\n",
    "            new_model.add(layer)\n",
    "        new_model.add(Dense(4096, activation='relu'))\n",
    "        new_model.add(Dropout(0.5))\n",
    "        new_model.add(Dense(4096, activation='relu'))\n",
    "        new_model.add(Dropout(0.5))\n",
    "    else:\n",
    "        for layer in model.layers[:-1]:\n",
    "            new_model.add(layer)\n",
    "\n",
    "    # Add in our own output layer\n",
    "    new_model.add(tf.keras.layers.Dense(output_size,activation='sigmoid'))\n",
    "\n",
    "    # Freeze all but num_active_layers layers\n",
    "    for layer_num, layer in enumerate(new_model.layers):\n",
    "        if layer_num < len(new_model.layers) - num_active_layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Setup optimizer, loss function, and metrics\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    loss = 'binary_crossentropy'\n",
    "    metrics = ['binary_accuracy']\n",
    "    new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup Different VGG19 Architecture\n",
    "vgg19 = tf.keras.applications.VGG19(include_top=True, weights='imagenet')\n",
    "\n",
    "baseline_model = setup_model(vgg19, input_shape=(224,224,3), output_size=1, dropout=False, num_active_layers=8, lr=1e-4)\n",
    "baseline_model.summary()\n",
    "\n",
    "dropout_vgg_model = setup_model(vgg19, input_shape=(224,224,3), output_size=1, dropout=True, num_active_layers=8, lr=1e-4)\n",
    "dropout_vgg_model.summary()\n",
    "\n",
    "dropout_lowlr_vgg_model = setup_model(vgg19, input_shape=(224,224,3), output_size=1, dropout=True, num_active_layers=8, lr=1e-5)\n",
    "dropout_lowlr_vgg_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Model Callbacks\n",
    "Below is some helper code that will allow us to add callbacks to our model. This will save the 'best' version of the model\n",
    "by comparing it to previous epochs of training. The 'patience' parameter tells the code how long to wait without seeing\n",
    "any improvements to the chosen metric before quitting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = f\"current_best.hdf5\"\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(weight_path,\n",
    "                                                monitor= 'val_loss',\n",
    "                                                verbose=1,\n",
    "                                                save_best_only=True,\n",
    "                                                mode= 'min',\n",
    "                                                save_weights_only = True)\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor= 'val_loss', mode= 'min', patience=25)\n",
    "\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save the Models\n",
    "Everything is already set up for this, all we have to do is run the model and look at the results below. I set up the ability\n",
    "to run all the available models. If you do not want to run any just comment them out. Also note that all models are saved\n",
    "to the models directory so you can just load in the models if you do not want to rerun them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model TODO: SETUP Baseline we originally used\n",
    "vgg_history = baseline_model.fit(train_generator, validation_data = next(validation_generator), epochs = 100, callbacks = callbacks_list)\n",
    "baseline_model.load_weights(weight_path)\n",
    "dropout_vgg_model.save(\"models/baseline_model.h5\")\n",
    "\n",
    "# Dropout with normal learning rate\n",
    "dropout_vgg_history = dropout_vgg_model.fit(train_generator, validation_data = next(validation_generator), epochs = 100, callbacks = callbacks_list)\n",
    "dropout_vgg_model.load_weights(weight_path)\n",
    "dropout_vgg_model.save(\"models/dropout_model.h5\")\n",
    "\n",
    "# Dropout with lower learning rate\n",
    "dropout_lowlr_vgg_history = dropout_lowlr_vgg_model.fit(train_generator, validation_data = next(validation_generator), epochs = 100, callbacks = callbacks_list)\n",
    "dropout_lowlr_vgg_model.load_weights(weight_path)\n",
    "dropout_lowlr_vgg_model.save(\"models/dropout_lowlr_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "Training the model results in a log of information on training loss, validation loss, training accuracy, and\n",
    "validation accuracy. You can view these results below. While these are helpful for showing us if our model is learning something,\n",
    "they are not very helpful when it comes to medical classification problems, especially if the disease you are trying to\n",
    "classify is very rare in the dataset (which is the case with pneumonia in this dataset). This is still helpful information,\n",
    "but we will look at better metrics below in the section on `Performance Statistics`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Model History\n",
    "def plot_history(model_history):\n",
    "    N = len(model_history.history['loss'])\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,N), model_history.history['loss'], label='train loss')\n",
    "    plt.plot(np.arange(0,N), model_history.history['val_loss'], label='valuation loss')\n",
    "    plt.plot(np.arange(0,N), model_history.history['binary_accuracy'], label='train accuracy')\n",
    "    plt.plot(np.arange(0,N), model_history.history['val_binary_accuracy'], label='valuation accuracy')\n",
    "    plt.title(\"Model Training Results\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss \\ Accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.plot()\n",
    "\n",
    "plot_history(vgg_history)\n",
    "plot_history(dropout_vgg_history)\n",
    "plot_history(dropout_lowlr_vgg_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Look at Performance Statistics\n",
    "Below we look at some performance statistics, more specifically the ROC curve along with AUC, the precision-recall curve,\n",
    "and the F1 scores for different thresholds. These statistics will help us decide a correct threshold for our\n",
    "classification problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_vgg_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-85f623455efb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Get Model Predictions\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mnew_vgg_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_weights\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweight_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mpred_Y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnew_vgg_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m256\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mplot_auc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'new_vgg_model' is not defined"
     ]
    }
   ],
   "source": [
    "#-----------         Functions for getting model predictions and plotting results       -------------#\n",
    "def get_model_predictions(model_filepath, validation_data):\n",
    "    \"\"\"\n",
    "    Takes in a filepath to the saved model, loads in the model, and gets predictions for all data in validation_generator\n",
    "    :param model_filepath: filepath to a saved model, must have .h5 extension\n",
    "    :param validation_data: Validation data to make predictions on. Can be anything Model.predict from Keras accepts. (array, tensor, generator, ect)\n",
    "    :return: a list of predictions for each input\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "    pred_y = model.predict(validation_data)\n",
    "    return [data for answer in pred_y for data in answer]\n",
    "\n",
    "def plot_roc_curve(model_name, true_y, pred_y):\n",
    "    \"\"\"\n",
    "    Plot the ROC curve along with the curves AUC for a given model. Note make sure true_y and pred_y are from the same model as model_name\n",
    "    :param model_name: Name of model used for saving plot\n",
    "    :param true_y: true labels for dataset\n",
    "    :param pred_y: predicted labels for dataset\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_y, pred_y)\n",
    "    ax.plot(fpr, tpr, label=f'{model_name} AUC: {metrics.auc(fpr,tpr)}')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    plt.savefig(f'images/{model_name}_roc.png')\n",
    "    return\n",
    "\n",
    "def plot_precision_recall_curve(model_name, true_y, pred_y):\n",
    "    \"\"\"\n",
    "    Plot the precision recall curve for a given model. Note make sure true_y and pred_y are from the same model as model_name\n",
    "    :param model_name: Name of model used for saving plot\n",
    "    :param true_y: true labels for dataset\n",
    "    :param pred_y: predicted labels for dataset\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(true_y, pred_y)\n",
    "    ax.plot(recall, precision, label=f'{model_name} AP Score: {metrics.average_precision_score(true_y,pred_y)}')\n",
    "    plt.legend()\n",
    "    ax.set_xlabel(\"Recall\")\n",
    "    ax.set_ylabel(\"Precision\")\n",
    "    plt.savefig(f'images/{model_name}_precision_recall.png')\n",
    "    return\n",
    "\n",
    "def calculate_f1_scores(precision, recall):\n",
    "    return [(2*p*r)/(p+r) for p,r in zip(precision,recall)]\n",
    "\n",
    "def plot_f1_score(model_name, true_y, pred_y):\n",
    "    \"\"\"\n",
    "    Plot F1 Scores for a given model. Note make sure true_y and pred_y are from the same model as model_name\n",
    "    F1 = 2*(precision*recall) / (precision + recall)\n",
    "    :param model_name: Name of model used for saving plot\n",
    "    :param true_y: true labels for dataset\n",
    "    :param pred_y: predicted labels for the dataset\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize=(7,7))\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(true_y,pred_y)\n",
    "    ax.plot(thresholds, precision[:-1], label=f'{model_name} Precision')\n",
    "    ax.plot(thresholds, recall[:-1], label=f'{model_name} Recall')\n",
    "    f1_scores = calculate_f1_scores(precision, recall)[:-1]\n",
    "    ax.plot(thresholds, f1_scores, label=f'{model_name} F1 Score')\n",
    "    plt.legend()\n",
    "    ax.set_xlabel(\"Threshold Values\")\n",
    "    plt.savefig(f'images/{model_name}_f1_score.png')\n",
    "    return max(f1_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate Plots for Models\n",
    "validation_generator = validation_idg.flow_from_dataframe(dataframe=val_df, directory=None,\n",
    "                                                      x_col='path', y_col='Pneumonia',\n",
    "                                                      class_mode='raw', target_size=IMG_SIZE, batch_size=len(val_df),\n",
    "                                                      shuffle = False)\n",
    "\n",
    "# Baseline Model Plots\n",
    "pred_y = get_model_predictions(\"models/baseline_model.h5\", validation_generator)\n",
    "true_y = val_df['Pneumonia'].values()\n",
    "plot_roc_curve('VGG19_baseline', true_y, pred_y)\n",
    "plot_precision_recall_curve('VGG19_baseline', true_y, pred_y)\n",
    "plot_f1_score('VGG19_baseline', true_y, pred_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dropout Model Plots\n",
    "pred_y = get_model_predictions(\"models/dropout_model.h5\", validation_generator)\n",
    "plot_roc_curve('VGG19_dropout', true_y, pred_y)\n",
    "plot_precision_recall_curve('VGG19_dropout', true_y, pred_y)\n",
    "plot_f1_score('VGG19_dropout', true_y, pred_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dropout with Low LR Model Plots\n",
    "pred_y = get_model_predictions(\"models/dropout_lowlr_model.h5\", validation_generator)\n",
    "plot_roc_curve('VGG19_dropout_lowlr', true_y, pred_y)\n",
    "plot_precision_recall_curve('VGG19_dropout_lowlr', true_y, pred_y)\n",
    "plot_f1_score('VGG19_dropout_lowlr', true_y, pred_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide on classification threshold\n",
    "It is difficult to decide on a classification threshold for this model because we do not entirely know what the use case\n",
    "is for our model. If this is a preliminary screening we want high recall so that we do not miss anyone that potentially has the disease.\n",
    "If the cost of the follow up exam is very expensive we want high precision because we do not want to waste patients money.\n",
    "Then again if missing a positive case leads to death of the patient we definitely want high recall to err on the side of caution.\n",
    "We could also just maximize the F1 score if we want to balance precision and recall.\n",
    "\n",
    "Based on the results from the graphs above I choose a threshold of ... to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Look at Example Cases based on Threshold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "## Find the threshold that optimize your model's performance,\n",
    "## and use that threshold to make binary classification. Make sure you take all your metrics into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Let's look at some examples of predicted v. true with our best model: \n",
    "\n",
    "# Todo\n",
    "\n",
    "# fig, m_axs = plt.subplots(10, 10, figsize = (16, 16))\n",
    "# i = 0\n",
    "# for (c_x, c_y, c_ax) in zip(valX[0:100], testY[0:100], m_axs.flatten()):\n",
    "#     c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "#     if c_y == 1: \n",
    "#         if pred_Y[i] > YOUR_THRESHOLD:\n",
    "#             c_ax.set_title('1, 1')\n",
    "#         else:\n",
    "#             c_ax.set_title('1, 0')\n",
    "#     else:\n",
    "#         if pred_Y[i] > YOUR_THRESHOLD: \n",
    "#             c_ax.set_title('0, 1')\n",
    "#         else:\n",
    "#             c_ax.set_title('0, 0')\n",
    "#     c_ax.axis('off')\n",
    "#     i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}